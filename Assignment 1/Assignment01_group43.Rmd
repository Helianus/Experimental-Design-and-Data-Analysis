---
title: "Assignment 1"
author: "Andrei Udriste, Xinyu Hu, Maria Gheorghe-Tudor - Group 43"
date: "2021/2/19"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### **Exercise 1.** *Birthweights*

The data set birthweight.txt contains the birthweights of 188 newborn babies. We are interested in finding the underlying (population) mean mu of birthweights. a) Check normality of the data. Compute a point estimate for mu. Derive, assuming normality (irrespective of your conclusion about normality of the data), a bounded 90% confidence interval for mu.

```{r}
data = read.table(file="birthweight.txt", header=TRUE)#Read the data from the file
qqnorm(data$birthweight)#Create a QQ plot to check the normality of the data
```

As it can be observed, the points in the *QQ-plot* creates a straight line, this means that the data has a normal distribution.

```{r}
data_mean = mean(data$birthweight)#Compute the estimate point for mu 
cat("mu =", data_mean)
```

The value of $mu$ is equal to 2913.293.

```{r}
error = qt(0.95, df=length(data$birthweight) - 1) * sd(data$birthweight) / sqrt(length(data$birthweight))#Compute the error for a 90% confidence interval
upper_bound = data_mean + error#Compute the upper bound of the confidence interval
lower_bound = data_mean - error#Compute the lower bound of te confidence interval
cat("90% confidence interval = (", lower_bound,",", upper_bound, ")")
```

After computing the confidence interval, it can be observed that 90% of the data is between 2829.202 and 2997.384.

b)  An expert claims that the mean birthweight is bigger than 2800, verify this claim by using a $t-test$. What is the outcome of the test if you take $alpha$ = 0.1? And other values of $alpha$?

```{r}
t.test(data$birthweight, mu=2800, alternative="greater")#Compute the t-test to check if the mean is bigger than 2800
```

If an $alpha$ of 0.1 is the set threshold, then the null hypothesis $H0$ is rejected and $H1$ fails to be rejected. In this case, the mean of the data is larger than 2800. The same result can be obtained if $alpha$\>=0.013, because the p-value is equal with 0.013. If $alpha$ has a value that is lower than 0.013 then we retain the null hypothesis $H0$.

c)  In the R-output of the test from b), also a confidence interval is given, but why is it different from the confidence interval found in a) and why is it one-sided?

The confidence interval found for point a) is calculated for a confidence interval of 90%, while the interval that is calculated when performing a t-test is 95% by default. In the case of the interval obtained at point b), one side of the interval is not defined because we are interested only in the values that are greater than our mean and we don't take into consideration if a value is smaller than our mean. Because of this the confidence interval, calculated at point b), the interval will be from the 10% quantile to infinity. This effect will also make the lower bound of the interval to be equal with the lower bound of the interval calculated at point a), even though they are calculated for different confidence intervals( 90%, 95% respectively).

This explanation can be tested simply by creating two t-tests, one with the default confidence level and one with a confidence level of 90%.

```{r}
t.test(data$birthweight)
t.test(data$birthweight, conf.level=0.9)
```

After realizing the two tests we can observe that the values of the confidence interval are different from one another. Another observation is that in comparison to point b), the interval is defined on both sides, because in this case, we are interested in values on both sides on the mean, not just bigger.

### **Exercise 2.** *Power function of the t-test*

We study the power function of the two-sample t-test (see Section 1.9 of Assignment 0). For n=m=30, mu=180, nu=175 and sd=5, generate 1000 samples x=rnorm(n,mu,sd) and y=rnorm(m,nu,sd), and record the 1000 p-values for testing H0 : mu=nu. You can evaluate the power (at point nu=175) of this t-test as fraction of p-values that are smaller than 0.05.

```{r}
#Initialize the variables that are going to be used to calculate the power
n = m = 30
mu = 180
nu = 175
sd = 5
B = 1000
p = numeric(B)

#Calculate the p-value for a "B" number of times
for(b in 1:B){
  x = rnorm(n, mu, sd)#Initialize "n" data points from a normal distribution with a mean "mu" and a standard deviation "sd".
  y = rnorm(m, nu, sd)#Initialize "m" data points from a normal distribution with a mean "nu" and a standard deviation "sd".
  p[b] = t.test(x, y, var.equal=TRUE)[[3]]#Obtain the p-value after doing the t-test
}
power = mean(p<0.05)#Calculate the power function
cat("The power of the test is equal with:", power)
```

a)  Set n=m=30, mu=180 and sd=5. Calculate now the power of the t-test for every value of nu in the grid seq(175,185,by=0.25). Plot the power as a function of nu.

```{r}
#Initialize the variables that are going to be used to calculate the power
n = m = 30
mu = 180
nu = 175
sd = 5
B = 1000
p = numeric(B)
nu = seq(175, 185, by=0.25)
power_a = numeric(length(nu))

#Calculate the power for each "nu" value
for(i in 1:length(nu)){
  #Calculate the p-value for a "B" number of times
  for(b in 1:B){
    x = rnorm(n, mu, sd)#Initialize "n" data points from a normal distribution with a mean "mu" and a standard deviation "sd".
    y = rnorm(m, nu[i], sd)#Initialize "m" data points from a normal distribution with a mean "nu" and a standard deviation "sd".
    p[b] = t.test(x, y, var.equal=TRUE)[[3]]#Obtain the p-value after doing the t-test
  }
  power_a[i] = mean(p<0.05)#Calculate the power function of a particular value of "nu"
}
```

b)  Set n=m=100, mu=180 and sd=5. Repeat the preceding exercise. Add the plot to the preceding plot.

```{r}
#Initialize the variables that are going to be used to calculate the power
n = m = 100
mu = 180
nu = 175
sd = 5
B = 1000
p = numeric(B)
nu = seq(175, 185, by=0.25)
power_b = numeric(length(nu))

#Calculate the power for each "nu" value
for(i in 1:length(nu)){
  #Calculate the p-value for a "B" number of times
  for(b in 1:B){
    x = rnorm(n, mu, sd)#Initialize "n" data points from a normal distribution with a mean "mu" and a standard deviation "sd".
    y = rnorm(m, nu[i], sd)#Initialize "m" data points from a normal distribution with a mean "nu" and a standard deviation "sd".
    p[b] = t.test(x, y, var.equal=TRUE)[[3]]#Obtain the p-value after doing the t-test
  }
  power_b[i] = mean(p<0.05)#Calculate the power function of a particular value of "nu"
}
```

c)  Set n=m=30, mu=180 and sd=15. Repeat the preceding exercise.

```{r}
#Initialize the variables that are going to be used to calculate the power
n = m = 30
mu = 180
nu = 175
sd = 15
B = 1000
p = numeric(B)
nu = seq(175, 185, by=0.25)
power_c = numeric(length(nu))

#Calculate the power for each "nu" value
for(i in 1:length(nu)){
  #Calculate the p-value for a "B" number of times
  for(b in 1:B){
    x = rnorm(n, mu, sd)#Initialize "n" data points from a normal distribution with a mean "mu" and a standard deviation "sd".
    y = rnorm(m, nu[i], sd)#Initialize "m" data points from a normal distribution with a mean "nu" and a standard deviation "sd".
    p[b] = t.test(x, y, var.equal=TRUE)[[3]]#Obtain the p-value after doing the t-test
  }
  power_c[i] = mean(p<0.05)#Calculate the power function of a particular value of "nu"
}
```

d)  Explain your findings.

```{r}
plot(nu, power_a, type="l", col="red", ylab="Power", xlab="nu")#Plot the power obtained from point "a" as a function of "nu"
points(nu, power_b, type="l", col="blue")#Plot the power obtained from point "b" as a function of "nu"
points(nu, power_c, type="l", col="green")#Plot the power obtained from point "c" as a function of "nu"
#legend(10,90, legend=c("Power a", "Power b", "Power c"), col=c("red", "blue", "green"))
```

-   The first observation illustrated in the plot, is that the power has a higher value as $nu$ value get closer to the extremities and is equal with 0 when $nu$ is equal with 180, this applies for all three cases.

-   Another observation is that all three lines have the shape of a bell curve but upside down.

-   If the red line is considered the base case, if we increase the number of samples, the blue line is obtained. In this case, the extremities get closer to 1 much faster. This indicates a higher power, so as it was expected: *increasing the sampling size increases the power level*.

-   In the case of the green line, we can observe the opposite. We have drop in power level compared to the red line. In conclusion *increasing the standard deviation will decrease the power function*.

### **Exercise 4.** *Energy drink*

To study the effect of energy drink a sample of 24 high school pupils were randomized to drinking either a softdrink or an energy drink after running for 60 meters. After half an hour they were asked to run again. For both sprints they were asked to sprint as fast they could, and the sprinting time was measured. The data is given in the file run.txt. [Courtesy class 5E, Stedelijk Gymnasium Leiden, 2010.]

a)  Disregarding the type of drink, test whether the run times before drink and after are correlated.

The first step is to create a histogram and a QQ-plot for the two data sets to verify normality of distribution.

```{r}
data_4 = read.table(file="run.txt", header=TRUE)#Read the data from run.txt
par(mfrow=c(2,2))
hist(data_4$before, main="Time before the drink", xlab="Measured time")#Creates a histogram from the data with the time before the drink
hist(data_4$after, main="Time after the drink", xlab="Measured time")#Creates a histogram from the data with the time after the drink
qqnorm(data_4$before)#Creates a QQ-norm from the time before before the drink
qqnorm(data_4$after)#Creates a QQ-norm from the time before after the drink
```

After looking at the histograms and the QQ-plots, it can be assumed that the distribution of the data is normal.

```{r}
par(mfrow=c(1,2))
boxplot(data_4$before, data_4$after, main="The two data sets")#Creates a boxplot from the data with the time before the drink
boxplot(data_4$before - data_4$after, main="The difference of the two data sets")

```

The next step is to analyze the data using a box plot. If we look at the three box plots we can observe a small variation between the measured time before and after drinking the energy drink. This could mean that the energy drink didn't have any real effect on the children, we can also test this by performing a two sided t-test on the obtained data and see if the p-value \> 0.05.

```{r}
t.test(data_4$before, data_4$after, paired=TRUE)
t.test(data_4$before - data_4$after)
```

After performing the t-test in two different ways and getting the same result we can conclude that we fail to reject the null hypothesis $H0$.

b)  Test separately, for both the softdrink and the energy drink conditions, whether there is a difference in speed in the two running tasks.

```{r}
energy_data_before = data_4$before[data_4[,3] == "energy"]
energy_data_after = data_4$after[data_4[,3] == "energy"]
par(mfrow=c(2,2))
hist(energy_data_before, main="Run time before energy drink", xlab="Measured time")
hist(energy_data_after, main="Run time after energy drink", xlab="Measured time")
boxplot(energy_data_before, energy_data_after, main="The two data sets")
boxplot(energy_data_before - energy_data_after, main="The difference of the two data sets")
```

The next step is to analyze the data concerning the energy drinks. If we look at the graphs we an observe that there is little difference between the measured time before and after drinking the energy drink. This could mean that the energy drink didn't have any real effect on the children, we can also test by performing a t-test on the obtained data and see if the p-value is not significant.

```{r}
t.test(energy_data_before, energy_data_after, paired=TRUE)
t.test(energy_data_before - energy_data_after)
```

After performing the two t-tests and obtaining the same p-value from both of them, we can conclude that we fail to reject $H0$.

```{r}
lemo_data_before = data_4$before[data_4[,3] == "lemo"]
lemo_data_after = data_4$after[data_4[,3] == "lemo"]
par(mfrow=c(2,2))
hist(lemo_data_before, main="Run time before placebo", xlab="Measured time")
hist(lemo_data_after, main="Run time after placebo", xlab="Measured time")
boxplot(lemo_data_before, lemo_data_after, main="The two data sets")
boxplot(lemo_data_before - lemo_data_after, main="The difference of the two data sets")
```

We could also try to analyze the data obtained from the children that took the placebo. If we look at the graphs, we an observe that the difference between the the measured time before and after drinking is very small. This is expected from the placebo, this can also be tested by performing a t-test on the obtained data and see if there is a p-value not significant.

```{r}
t.test(lemo_data_before, lemo_data_after, paired=TRUE)
t.test(lemo_data_before - lemo_data_after)
```

After performing the two t-tests and obtaining the same p-value from both of them we can get to the conclusion that we fail to reject the null hypothesis $H0$.

c)  For each pupil compute the time difference between the two running tasks. Test whether these time differences are effected by the type of drink.

```{r}
child_time = numeric(length(data_4$before))
for(i in 1:length(data_4$before)){
  child_time[i] =  data_4$before[i] - data_4$after[i]
}

lemo_child_time = child_time[data_4[,3] == "lemo"]
energy_child_time = child_time[data_4[,3] == "energy"]

par(mfrow=c(2,2))
hist(lemo_child_time, main="Run time placebo", xlab="Measured time")
hist(energy_child_time, main="Run time energy drink", xlab="Measured time")
boxplot(lemo_child_time, energy_child_time, main="The two data sets")
boxplot(lemo_child_time - energy_child_time, main="The difference of the two data sets")
```

The last method to see if there is any difference between the energy drink and the placebo is to test each child individually and compare the results. After looking at the histograms and the three box plot we can observe that the difference between the two data sets is very small. Due to this, we can assume assume that there is no difference between them, but we have to test this using the t-test and see if the p-values \> 0.05.

```{r}
t.test(lemo_child_time, energy_child_time, paired=TRUE)
t.test(lemo_child_time - energy_child_time)
```

After performing the two t-tests and obtaining the same p-value from both of them we can get to the conclusion that we fail to reject the null hypothesis $H0$.

d)  Can you think of a plausible objection to the design of the experiment in b) if the main aim was to test whether drinking the energy drink speeds up the running? Is there a similar objection to the design of the experiment in c)? Comment on all your findings in this exercise.

Yes, there are two improvement that can be applied for design experiment for point b) and c). The first one is to implement *crossover experimental design*, in this way we can eliminate bias. The second improvement is to increase the sample size so that we can have a better representation of the two distributions.

### **Exercise 5.** *Chick weights*

The dataset chickwts is a data frame included in the standard R installation, to view it, type chickwts at the R prompt. This data frame contains 71 observations on newly-hatched chicks which were randomly allocated among six groups. Each group was given a different feed supplement for six weeks, after which their weight (in grams) was measured. The data frame consists of a numeric column giving the weights, and a factor column giving the name of the feed supplement.

a)  Test whether the distributions of the chicken weights for meatmeal and sunflower groups are different by performing three tests: the two samples t-test (argue whether the data are paired or not), the Mann-Whitney test and the Kolmogorov-Smirnov test. Comment on your findings.

```{r}
data("chickwts")
meatmeal = chickwts$weight[chickwts$feed == "meatmeal"]
sunflower = chickwts$weight[chickwts$feed == "sunflower"]
boxplot(meatmeal, sunflower, names=c("meatmeal", "sunflower"))
```

```{r}
t.test(meatmeal, sunflower, paired=FALSE)
```

Since the Welch Two Sample t-test has $p$-value=0.04441 \< 0.05, it is the case to reject $H_0$. The conclusion should be there exist certain difference between the meatmeal and sunflower. Additionally, the data are not paired, because if we set "paired=TRUE", we would get an error message- "not all arguments have the same length".

```{r}
wilcox.test(meatmeal, sunflower)
```

Mann-Whitney test has a $p$-value = 0.06882 \> 0.05, so the conclusion is that there is no such significant difference between two groups.

```{r}
ks.test(meatmeal,sunflower)
```

Kolmogorov-Smirnov test has a $p$-value = 0.1085 \< 0.05. From this result we can conclude that the two populations are extremely unsymmetrical in shapes.

c)  Conduct a one-way ANOVA to determine whether the type of feed supplement has an effect on the weight of the chicks. Give the estimated chick weights for each of the six feed supplements. What is the best feed supplement?

```{r}
chickaov=lm(weight ~ feed, data=chickwts)
anova(chickaov)
```

By conducting the one-way ANOVA, it is easy to see that the $p$-value = 5.936e-10 \< 0.05, which tells that there exist at least such a type has an extremely different average weight.

```{r}
library(ggplot2)
library(ggthemes)
library(dplyr)
cdata = tbl_df(chickwts)
cdata.wt.feed = cdata %>%
  ggplot(aes(x=feed, y=weight)) +
  geom_count(color="red") +
  labs(title="Relationship Between Chick Weight & Type of Feed",
       x="Feed Type", y="Weight in Grams") + 
  theme_calc()
cdata.wt.feed
```

The above plot shows that the casein and sunflower are the best feed supplement.

c)  Check the ANOVA model assumptions by using relevant diagnostic tools.

```{r}
caov = aov(weight~feed, data=chickwts)
plot(caov)
```

These plots shows that the ANOVA model assumptions is in line with expectations. In the case like this, we can conclude that values have equal variance.

```{r}
summary(caov)
```

Additionally, since the $p$-value \< 0.05, it also shows the normality of the values.

d)  Does the Kruskal-Wallis test arrive at the same conclusion about the effect of feed supplement as the test in b)? Explain possible differences between conclusions of the Kruskal-Wallis and ANOVA tests.

```{r}
kruskal.test(weight ~ feed, data=chickwts) 
```

Kruskal-Wallis test has a $p$-value = 5.113e-07 \< 0.05, which means there exist such a feed influenced the weight. And the one-way ANOVA also shows the same conclusion. On the other hand, Kruskal-Wallis test is based on ranks instead of normality as ANOVA. It means that the ANOVA tested the normality of values from means, but Kruskal-Wallis tested on comparison of the ranks of the means.
