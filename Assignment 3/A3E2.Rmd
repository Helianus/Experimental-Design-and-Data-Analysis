---
title: "A3E1"
author: "Andrei Udriste"
date: "2021/3/16"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=6, fig.height=4, fig.align = "center")
library(knitr)
```

# Exercise 2.

## a)

```{r,echo=FALSE}
data = read.table('titanic.txt', header=T)
attach(data)
survivars_age = Age[Survived == 1]
not_survivars_age = Age[Survived == 0]
boxplot(Age, survivars_age, not_survivars_age)
```

In boxplot (1) we have the age of all the passengers, (2) represent the ages of all surviving passengers and in (3) we have the ages of the passengers that didn't survive. It can be observed from the boxplot above tat the age didn't have any major impact in someone surviving or not.

```{r}
surv_fem = table(Survived[Sex == "female"])
surv_men = table(Survived[Sex == "male"])

par(mfrow=c(1,2))
barplot(surv_fem , ylab="Number of survivors", xlab="Female")
barplot(surv_men, ylab="Number of survivors", xlab="Men")
```

We can observe a clear difference in between the two barplots, to be more precise the number of female survivors is much more higher than the one of male survivors. Contrary in the case of non-surviving passengers the number of females is smaller than the number of males.

```{r}
surv_1cls = table(Survived[PClass == "1st"])
surv_2cls = table(Survived[PClass == "2nd"])
surv_3cls = table(Survived[PClass == "3rd"])

par(mfrow=c(1,3))
barplot(surv_1cls, ylab="Number of survivors", xlab="1st Class")
barplot(surv_2cls, ylab="Number of survivors", xlab="2nd Class")
barplot(surv_3cls, ylab="Number of survivors", xlab="3rd Class")
```

More differences can be observed in the survival rates of the passengers from the 3 classes. In the 1 class we can see that the number of survivors is higher than the number of non-survivors, unfortunately we can not say the same for the other 2 classes where the number non-survivors is higher than the number of survivors. This can be observed mostly in the 3rd class where the number of non-survivors is 4 times bigger than the number of survivors. One common thing that can be observed for all classes is that the number of survivors is between 100 and 200 for all 3 of them.

## b)

```{r}
fact_PClass = factor(PClass)
fact_Sex = factor(Sex)
fact_Age = factor(Age)
titglm = glm(Survived ~ fact_PClass + fact_Sex + fact_Age, data = data, family=binomial)
summary(titglm, maxsum = 10)
```

Because of the big number of variable that appear in the summary is recommended to use Age as a numerical variable rather than a factorial one, but this change will affect the model, some of the rows will not appear, because the Age is not present (NA), and the glm model will just ignore those rows.

```{r}
titglm_f = glm(Survived ~ fact_PClass + fact_Sex + Age, data = data, family=binomial)
summary(titglm_f)
```

After computing the smaller model we can compute all the odds by summing all the Estimates of the factors that are of interest and applying exp(sum), which translates to e to the power of the sum.

```{r}
exp(coef(titglm_f))
```

```{r}
cat("odds of 1st class + female + age =", exp(3.759662 - 0 - 0 - 0.039177), "\n")
cat("odds of 1st class + male + age =", (3.759662 - 0 - 2.631357 - 0.039177), "\n")
cat("odds of 2st class + female + age =", exp(3.759662 - 1.291962 - 0 - 0.039177), "\n")
cat("odds of 2st class + male + age =", exp(3.759662 - 1.291962 - 2.631357 - 0.039177), "\n")
cat("odds of 3st class + female + age =", exp(3.759662 - 2.521419 - 0 - 0.039177), "\n")
cat("odds of 3st class + male + age =", exp(3.759662 - 2.521419 - 2.631357 - 0.039177), "\n")
```

After computing the we can observe that the same trends that where present in the graphs from point **a)** are present also here. More exactly the female have a higher odds than male and as the class is lower the odds of survival also decrease. Based on this we can see that the biggest odds of survival are for the females from the 1st class, while the worst ones are for the male in the 3rd class.

## c)

```{r}
glm1 = glm(Survived ~ Age * fact_Sex, data = data, family=binomial)
anova(glm1, test="Chisq")
```

After verifying the interaction between the factors (Sex) and the numerical variable (Age) we obtain a $p$-value of 5.64e-07 which is smaller than 0.05. Because of this we can conclude that we will reject $H0$ so the numerical variable Age does have a big influence over the outcome so it is not recommended to eliminate it from the model.

```{r}
glm2 = glm(Survived ~ Age * fact_PClass, data = data, family=binomial)
anova(glm2, test="Chisq")
```

After verifying the interaction between the two factors (Class) and the numerical variable (Age) we obtain a $p$-value of 0.558 which is bigger than 0.05. Because of this we can conclude that we will not reject $H0$ so the numerical variable Age does not have a big influence over the outcome so we can eliminate it from the model.

Because of the interaction between Age and PClass we will create a model that is not dependent on Age.

```{r,echo=FALSE}
titglm2 = glm(Survived ~ fact_PClass + fact_Sex, data = data, family=binomial)
summary(titglm2)
```

Because the variable Age doesn't have major influence in the outcome we can create a model that does not include it.

```{r}
p1m = predict(titglm2, data.frame(fact_PClass = "1st", fact_Sex = "male", Age = "53"), type="response")
p2m = predict(titglm2, data.frame(fact_PClass = "2nd", fact_Sex = "male", Age = "53"), type="response")
p3m = predict(titglm2, data.frame(fact_PClass = "3rd", fact_Sex = "male", Age = "53"), type="response")
p1f = predict(titglm2, data.frame(fact_PClass = "1st", fact_Sex = "female", Age = "53"), type="response")
p2f = predict(titglm2, data.frame(fact_PClass = "2nd", fact_Sex = "female", Age = "53"), type="response")
p3f = predict(titglm2, data.frame(fact_PClass = "3rd", fact_Sex = "female", Age = "53"), type="response")
```

We can use the **predict()** function to predict information about a specific group of passengers. But the problem is that the predicted value is given in probability instead of odds, so we have to transform it in odds.

```{r}
cat("odds of 1st class + male + age(53) =", p1m / (1 - p1m), "\n")
cat("odds of 2nd class + male + age(53) =", p2m / (1 - p2m), "\n")
cat("odds of 3rd class + male + age(53) =", p3m / (1 - p3m), "\n")
cat("odds of 1st class + female + age(53) =", p1f / (1 - p1f), "\n")
cat("odds of 2nd class + female + age(53) =", p2f / (1 - p2f), "\n")
cat("odds of 3rd class + female + age(53) =", p3f / (1 - p3f), "\n")
```

After transforming the probabilities in odds it can be observed that the same pattern is maintained, mainly that the odds for survival for females are higher than the ones for males and as the class increase the odds decrease.

## d)

One method to predict the survival status would be to split the data in 3 categories:

-   Training data

-   Validation data

-   Test data

THe training data can be used to create a model and to optimize it (obtain the maximum likelihood of teta_hat). After the model has been train we can try and use the validation data to predict how will the model predict the outcome. If the accuracy of the model on the validation data is as good or better than the imposed threshold we can move to the next step, test the model on the test data. This is one of the most important steps, because it can offer us a pretty good measurement of the model accuracy. It is recommended to not use the test data more than a few times (is ideal to use it only once) to test the model.

If the model offers a good accuracy on the test data then we can say that our model will perform pretty well in a real scenario.

## e)

```{r,echo=FALSE}
tot_class = xtabs(~ Survived + fact_PClass)
tot_class
```

Using the contingency table for the two factors PClass and Survived it can be observed that the trends present in the graphs presented above is maintained.

```{r}
tot_ch = chisq.test(tot_class)
tot_ch
```

Because the $p$-value is equal with 2.2e-16 which is smaller then 0.05, it can be concluded that we reject the null hypotheses H0. This means that there is a dependence between the two factors PClass and Survived.

```{r}
tot_sex = xtabs(~ Survived + fact_Sex)
tot_sex
```

Using the contingency table for the two factors Sex and Survived it can be observed that the trends present in the graphs presented above is maintained.

```{r}
fisher.test(tot_sex)
```

After applying the Fisher test we obtain a $p$-value equal with 2.2e-16 which is smaller then 0.05, so it can be concluded that we reject the null hypotheses H0. This means that there is a dependence between the two factors Sex and Survived.

## f)

Yes, the second approach is wring because it only test one factor at a time instead of both at the same time. On advantage of this approach is that we can test and see the influence of each factor separately on the Survived status.Based on this approach we can discard the factors that do not influence the outcome. One disadvantage is that we can only test one variable at at time and we can not see if there is any influence between two factors (ex: between PClass and Sex).

The first method is much more suitable for this kind of analyses, having the advantage that we can also see the influence that different factors have on the outcome. But of course that there are also disadvantages, mainly that we may take into account factors that do not have a big influence on our output (ex: Age).
